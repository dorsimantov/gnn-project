model:
  in_channels: 16  # Size of each input sample
  hidden_channels: 32  # Size of each hidden sample
  num_layers: 3  # Number of message passing layers
  out_channels: 8  # Output feature dimension, set to None if not needed
  v2: False  # Set to True to use GATv2Conv
  dropout: 0.2  # Dropout probability
  act: "relu"  # Activation function
  act_first: False  # Apply activation before normalization
  act_kwargs: {}  # Optional kwargs for activation function
  norm: 'LayerNorm'  # Normalization function, TODO
  norm_kwargs: {}  # Optional kwargs for normalization function
  jk: 'cat'  # Jumping Knowledge mode, TODO

training:
  epochs: 100
  learning_rate: 0.01
  weight_decay: 0.0005
  device: "cuda"  # Set "cpu" if not using GPU
